{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1dvM15NaJCLa9FGiq8q0SHpJt6hCiFIN_","timestamp":1747623679641},{"file_id":"1XNCDLNp1T2F_MPYGlxrw-Zejh_hRQjAb","timestamp":1747590907427},{"file_id":"1d6vsb-geXD_2DCylbBv4bVj4I81O1rzJ","timestamp":1747583203828}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install pdf2image\n","!apt-get install -y poppler-utils"],"metadata":{"id":"h1bQ1dUbvJ4B"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qn9p2CCAMtg7"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406],\n","                         [0.229, 0.224, 0.225])\n","])\n","\n","train_path = \"/content/drive/MyDrive/SAFE_AI(Project_proposal)/CVPR_Dataset_LowRes/train\"\n","test_path = \"/content/drive/MyDrive/SAFE_AI(Project_proposal)/CVPR_Dataset_LowRes/test\"\n","\n","train_dataset = datasets.ImageFolder(train_path, transform=transform)\n","test_dataset = datasets.ImageFolder(test_path, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32)"],"metadata":{"id":"jdCmkPXnM2wW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def conv3x3(in_planes, out_planes, stride, padding=1, bias = False):\n","    return nn.Conv2d(in_planes, out_planes, \\\n","        kernel_size = 3,                    \\\n","        stride      = stride,               \\\n","        padding     = padding,              \\\n","        bias        = bias\n","    )\n","\n","def conv1x1(in_planes, out_planes, stride, padding=0, bias = False):\n","    return nn.Conv2d(in_planes, out_planes, \\\n","        kernel_size = 1,                    \\\n","        stride      = stride,               \\\n","        padding     = padding,              \\\n","        bias        = bias\n","    )\n","\n","class BasicBlock(nn.Module):\n","    mul = 1\n","    def __init__(self, in_planes, out_planes, stride = 1):\n","        super(BasicBlock, self).__init__()\n","\n","        self.conv1 = conv3x3(in_planes, out_planes, stride)\n","        self.conv2 = conv3x3(out_planes, out_planes, 1)\n","\n","        self.bn1   = nn.BatchNorm2d(out_planes)\n","        self.bn2   = nn.BatchNorm2d(out_planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1:\n","            self.shortcut = nn.Sequential(\n","                conv1x1(in_planes, out_planes, stride),\n","                nn.BatchNorm2d(out_planes)\n","            )\n","\n","    def forward(self, x):\n","        out  = self.conv1(x)\n","        out  = self.bn1(out)\n","        out  = F.relu(out)\n","        out  = self.conv2(out)\n","        out  = self.bn2(out)\n","        out += self.shortcut(x)\n","        out  = F.relu(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes = 10):\n","        super(ResNet, self).__init__()\n","\n","        self.in_planes = 64\n","\n","        self.conv    = nn.Conv2d(3, self.in_planes, kernel_size = 7, stride = 2, padding = 3)\n","        self.bn      = nn.BatchNorm2d(self.in_planes)\n","        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","\n","        _layers = []\n","        outputs, strides = [64, 128, 256, 512], [1, 2, 2, 2]\n","        for i in range(4):\n","            _layers.append(self._make_layer(block, outputs[i], num_blocks[i], stride=strides[i]))\n","        self.layers = nn.Sequential(*_layers)\n","\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.linear  = nn.Linear(512 * block.mul, num_classes)\n","\n","    def _make_layer(self, block, out_planes, num_block, stride):\n","        layers  = [ block(self.in_planes, out_planes, stride) ]\n","        self.in_planes = block.mul * out_planes\n","        for i in range(num_block - 1):\n","            layers.append(block(self.in_planes, out_planes, 1))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = self.conv(x)\n","        out = self.bn(out)\n","        out = F.relu(out)\n","        out = self.maxpool(out)\n","        out = self.layers(out)\n","        out = self.avgpool(out)\n","        out = torch.flatten(out, 1)\n","        out = self.linear(out)\n","        return out\n","\n","def ResNet18():\n","    return ResNet(BasicBlock, [2, 2, 2, 2])\n",""],"metadata":{"id":"qF76XnmUM9Yn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = ResNet(BasicBlock, [2,2,2,2], num_classes=2).to(device)\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.005)\n","\n","num_epochs = 5\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    train_acc = 100 * correct / total\n","    print(f\"[Epoch {epoch+1}] Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_acc:.2f}%\")"],"metadata":{"id":"yTN2qr_eM_hE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","test_acc = 100 * correct / total\n","print(f\"테스트 정확도: {test_acc:.2f}%\")"],"metadata":{"id":"NWsYOBOlNA5_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model.state_dict(), \"/content/drive/MyDrive/SAFE_AI(Project_proposal)/Models/cvpr_ResNet18_model.pt\")"],"metadata":{"id":"LAWmJdtjNCC1"},"execution_count":null,"outputs":[]}]}