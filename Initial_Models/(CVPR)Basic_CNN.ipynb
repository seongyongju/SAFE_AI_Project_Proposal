{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1d6vsb-geXD_2DCylbBv4bVj4I81O1rzJ","timestamp":1747648374023}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install pdf2image\n","!apt-get install -y poppler-utils"],"metadata":{"id":"h1bQ1dUbvJ4B"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qn9p2CCAMtg7"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import numpy as np\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406],\n","                         [0.229, 0.224, 0.225])\n","])\n","\n","train_path = \"/content/drive/MyDrive/SAFE_AI(Project_proposal)/CVPR_Dataset_LowRes/train\"\n","test_path = \"/content/drive/MyDrive/SAFE_AI(Project_proposal)/CVPR_Dataset_LowRes/test\"\n","\n","train_dataset = datasets.ImageFolder(train_path, transform=transform)\n","test_dataset = datasets.ImageFolder(test_path, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32)"],"metadata":{"id":"jdCmkPXnM2wW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(3, 16, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(16, 32, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(32 * 56 * 56, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 2)\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.fc(x)\n","        return x"],"metadata":{"id":"qF76XnmUM9Yn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = CNN().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","num_epochs = 5\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    train_acc = 100 * correct / total\n","    print(f\"[Epoch {epoch+1}] Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_acc:.2f}%\")"],"metadata":{"id":"yTN2qr_eM_hE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","test_acc = 100 * correct / total\n","print(f\"정확도: {test_acc:.2f}%\")"],"metadata":{"id":"NWsYOBOlNA5_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model.state_dict(), \"/content/drive/MyDrive/SAFE_AI(Project_proposal)/cvpr_cnn_model.pt\")"],"metadata":{"id":"LAWmJdtjNCC1"},"execution_count":null,"outputs":[]}]}
