{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1EDtDrz-_4oPswR6KTKuo-l8UU3iVJubT","timestamp":1747638323603}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install pdf2image\n","!apt-get install -y poppler-utils"],"metadata":{"id":"h1bQ1dUbvJ4B"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qn9p2CCAMtg7"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import os\n","from PIL import Image\n","from torch.utils.data import Dataset\n","import torchvision.transforms as transforms\n","\n","class FilenameLabelDataset(Dataset):\n","    def __init__(self, folder_path, transform=None):\n","        self.folder_path = folder_path\n","        self.transform = transform\n","        self.samples = []\n","\n","        for file in os.listdir(folder_path):\n","            if file.endswith((\".jpg\", \".png\", \".jpeg\")):\n","                label = 0 if \"Accepted\" in file else 1\n","                self.samples.append((os.path.join(folder_path, file), label))\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        img_path, label = self.samples[idx]\n","        image = Image.open(img_path).convert(\"RGB\")\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label\n","\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406],\n","                         [0.229, 0.224, 0.225])\n","])\n","\n","train_path = \"/content/drive/MyDrive/SAFE_AI(Project_proposal)/ICLR_Dataset_LowRes/train\"\n","test_path = \"/content/drive/MyDrive/SAFE_AI(Project_proposal)/ICLR_Dataset_LowRes/test\"\n","\n","train_dataset = FilenameLabelDataset(train_path, transform=transform)\n","test_dataset = FilenameLabelDataset(test_path, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32)"],"metadata":{"id":"jdCmkPXnM2wW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CNN_FT(nn.Module):\n","    def __init__(self, p_dropout=0.3):\n","        super().__init__()\n","\n","        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n","        self.bn1   = nn.BatchNorm2d(16)\n","        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n","        self.bn2   = nn.BatchNorm2d(32)\n","\n","        self.flat  = nn.Flatten()\n","        self.fc1   = nn.Linear(32*56*56, 128)\n","        self.dp1   = nn.Dropout(p_dropout)\n","        self.fc2   = nn.Linear(128, 2)\n","\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, m):\n","        \"\"\"Kaiming (He) initialization for ReLU 계열\"\"\"\n","        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n","            nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n","            if m.bias is not None:\n","                nn.init.constant_(m.bias, 0)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.max_pool2d(x, 2)\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.max_pool2d(x, 2)\n","\n","        x = self.flat(x)\n","        x = F.relu(self.fc1(x))\n","        x = self.dp1(x)\n","        x = self.fc2(x)\n","        return x"],"metadata":{"id":"qF76XnmUM9Yn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model  = CNN_FT(p_dropout=0.3).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0005)\n","\n","num_epochs = 5\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    train_acc = 100 * correct / total\n","    print(f\"[Epoch {epoch+1}] Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_acc:.2f}%\")"],"metadata":{"id":"yTN2qr_eM_hE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","test_acc = 100 * correct / total\n","print(f\"테스트 정확도: {test_acc:.2f}%\")"],"metadata":{"id":"NWsYOBOlNA5_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model.state_dict(), \"/content/drive/MyDrive/SAFE_AI(Project_proposal)/Models/NeurIPS_CNN_model_Tuning_VER.pt\")"],"metadata":{"id":"LAWmJdtjNCC1"},"execution_count":null,"outputs":[]}]}